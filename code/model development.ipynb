{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18425143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = random.randint(2000, 100000)\n",
    "print(rs)\n",
    "# rs = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799856e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './P10/plan2/'\n",
    "testandvali_dir = './P10/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325552bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['cl', 'ra', 'me']\n",
    "datasets = ['test', 'vali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f8950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['cl', 'ra', 'me', 'clra', 'clme', 'rame','clrame']\n",
    "datasets = ['train', 'test', 'vali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95106240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve,average_precision_score\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,roc_auc_score,accuracy_score,roc_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight = 'balanced_subsample'\n",
    "class_weight = 'balanced'\n",
    "results_df = pd.DataFrame(columns=['dataset', 'Key', 'max_depth', 'max_features', 'n_estimators', 'Best Score'])\n",
    "S\n",
    "\n",
    "for key in types:\n",
    "    data = pd.read_csv(data_dir+f'train_{key}_RFE.csv')\n",
    "    X = data[data.columns[2:]]\n",
    "    y = data['label']\n",
    "    X = X.apply(pd.to_numeric, errors='ignore')\n",
    "    colNames = X.columns\n",
    "    X = X.fillna(0)\n",
    "    X = X.astype(np.float64)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X = pd.DataFrame(X)\n",
    "    X.columns = colNames\n",
    "    print(X.shape)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': range(1, 3),\n",
    "        'max_depth': range(1, 3),\n",
    "        'max_features': range(1, 3)\n",
    "    }\n",
    "\n",
    "    rfc = RandomForestClassifier(random_state=rs, n_jobs=-1,class_weight=class_weight)\n",
    "\n",
    "    GS = GridSearchCV(rfc, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    GS.fit(X, y)\n",
    "\n",
    "    best_params = GS.best_params_\n",
    "    best_score = GS.best_score_\n",
    "\n",
    "    result = pd.DataFrame({'dataset': ['train'],\n",
    "                           'Key': [key],\n",
    "                           'max_depth': [best_params['max_depth']],\n",
    "                           'max_features': [best_params['max_features']],\n",
    "                           'n_estimators': [best_params['n_estimators']],\n",
    "                           'Best Score': [best_score]})\n",
    "    results_df = pd.concat([results_df, result], ignore_index=True)\n",
    "    \n",
    "    best_params = GS.best_params_\n",
    "    joblib.dump(best_params, data_dir+f'model1/rf_train_{key}_best_params.joblib')\n",
    "    \n",
    "    forest = RandomForestClassifier(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        max_features=best_params['max_features'],\n",
    "        random_state=rs,\n",
    "        n_jobs=-1,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "\n",
    "    forest.fit(X, y)\n",
    "    joblib.dump(forest, data_dir+f'model1/rf_train_{key}.pkl')\n",
    "    \n",
    "    forest_y_pre = forest.predict(X)\n",
    "    forest_y_proba = forest.predict_proba(X)\n",
    "\n",
    "    forest_acc = accuracy_score(y,forest_y_pre)\n",
    "    forest_preci = precision_score(y,forest_y_pre)\n",
    "    forest_recall = recall_score(y,forest_y_pre)\n",
    "    forest_f1 = f1_score(y,forest_y_pre)\n",
    "    forest_auc = roc_auc_score(y,forest_y_proba[:,1])\n",
    "    \n",
    "    forest_cm = confusion_matrix(y, forest_y_pre)\n",
    "\n",
    "    true_negative = forest_cm[0, 0]\n",
    "    false_positive = forest_cm[0, 1]\n",
    "    false_negative = forest_cm[1, 0]\n",
    "    true_positive = forest_cm[1, 1]\n",
    "\n",
    "    sensitivity = true_positive / (true_positive + false_negative)\n",
    "\n",
    "    specificity = true_negative / (true_negative + false_positive)\n",
    "\n",
    "    ppv = true_positive / (true_positive + false_positive)\n",
    "\n",
    "    npv = true_negative / (true_negative + false_negative)\n",
    "    \n",
    "    metric = pd.DataFrame({'dataset': ['train'],\n",
    "                           'Key': [key],\n",
    "                           'acc': [forest_acc],\n",
    "                           'auc': [forest_auc],\n",
    "                           'forest_preci': [forest_preci],\n",
    "                           'sensitivity': [sensitivity],\n",
    "                           'specificity': [specificity],\n",
    "                           'ppv': [ppv],\n",
    "                           'npv': [npv],\n",
    "                            'forest_f1': [forest_f1]})\n",
    "    metrics_df = pd.concat([metrics_df, metric], ignore_index=True)\n",
    "    \n",
    "print(results_df)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6370c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['cl', 'ra', 'me', 'clra', 'clme', 'rame','clrame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e84f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = metrics_df[metrics_df['dataset'] != 'test']\n",
    "for key in models:\n",
    "    print(key)\n",
    "    data = pd.read_csv(data_dir+f'test_{key}_RFE.csv')\n",
    "    X = data[data.columns[2:]]\n",
    "    y = data['label']\n",
    "    X = X.apply(pd.to_numeric,errors = 'ignore') \n",
    "    colNames = X.columns \n",
    "    X = X.fillna(0)\n",
    "    X = X.astype(np.float64)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X = pd.DataFrame(X)\n",
    "    X.columns = colNames\n",
    "    print(X.shape)\n",
    "    \n",
    "    forest = joblib.load(data_dir+f'model1/rf_train_{key}.pkl')\n",
    "    \n",
    "    forest_y_pre = forest.predict(X)\n",
    "    forest_y_proba = forest.predict_proba(X)\n",
    "\n",
    "    forest_acc = accuracy_score(y,forest_y_pre)\n",
    "    forest_preci = precision_score(y,forest_y_pre)\n",
    "    forest_recall = recall_score(y,forest_y_pre)\n",
    "    forest_f1 = f1_score(y,forest_y_pre)\n",
    "    forest_auc = roc_auc_score(y,forest_y_proba[:,1])\n",
    "    \n",
    "    forest_cm = confusion_matrix(y, forest_y_pre)\n",
    "\n",
    "    true_negative = forest_cm[0, 0]\n",
    "    false_positive = forest_cm[0, 1]\n",
    "    false_negative = forest_cm[1, 0]\n",
    "    true_positive = forest_cm[1, 1]\n",
    "\n",
    "    sensitivity = true_positive / (true_positive + false_negative)\n",
    "\n",
    "    specificity = true_negative / (true_negative + false_positive)\n",
    "\n",
    "    ppv = true_positive / (true_positive + false_positive)\n",
    "\n",
    "    npv = true_negative / (true_negative + false_negative)\n",
    "    \n",
    "    metric = pd.DataFrame({'dataset': ['test'],\n",
    "                           'Key': [key],\n",
    "                           'acc': [forest_acc],\n",
    "                           'auc': [forest_auc],\n",
    "                           'forest_preci': [forest_preci],\n",
    "                           'sensitivity': [sensitivity],\n",
    "                           'specificity': [specificity],\n",
    "                           'ppv': [ppv],\n",
    "                           'npv': [npv],\n",
    "                            'forest_f1': [forest_f1]})\n",
    "    metrics_df = pd.concat([metrics_df, metric], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef072943",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = metrics_df[metrics_df['dataset'] != 'vali']\n",
    "for key in models:\n",
    "    data = pd.read_csv(data_dir+f'vali_{key}_RFE.csv')\n",
    "    X = data[data.columns[2:]]\n",
    "    y = data['label']\n",
    "    X = X.apply(pd.to_numeric,errors = 'ignore') \n",
    "    colNames = X.columns \n",
    "    X = X.fillna(0)\n",
    "    X = X.astype(np.float64)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X = pd.DataFrame(X)\n",
    "    X.columns = colNames\n",
    "    print(X.shape)\n",
    "    \n",
    "    forest = joblib.load(data_dir+f'model1/rf_train_{key}.pkl')\n",
    "    \n",
    "    forest_y_pre = forest.predict(X)\n",
    "    forest_y_proba = forest.predict_proba(X)\n",
    "\n",
    "    forest_acc = accuracy_score(y,forest_y_pre)\n",
    "    forest_preci = precision_score(y,forest_y_pre)\n",
    "    forest_recall = recall_score(y,forest_y_pre)\n",
    "    forest_f1 = f1_score(y,forest_y_pre)\n",
    "    forest_auc = roc_auc_score(y,forest_y_proba[:,1])\n",
    "    \n",
    "    forest_cm = confusion_matrix(y, forest_y_pre)\n",
    "\n",
    "    true_negative = forest_cm[0, 0]\n",
    "    false_positive = forest_cm[0, 1]\n",
    "    false_negative = forest_cm[1, 0]\n",
    "    true_positive = forest_cm[1, 1]\n",
    "\n",
    "    sensitivity = true_positive / (true_positive + false_negative)\n",
    "\n",
    "    specificity = true_negative / (true_negative + false_positive)\n",
    "\n",
    "    ppv = true_positive / (true_positive + false_positive)\n",
    "\n",
    "    npv = true_negative / (true_negative + false_negative)\n",
    "    \n",
    "    metric = pd.DataFrame({'dataset': ['vali'],\n",
    "                           'Key': [key],\n",
    "                           'acc': [forest_acc],\n",
    "                           'auc': [forest_auc],\n",
    "                           'forest_preci': [forest_preci],\n",
    "                           'sensitivity': [sensitivity],\n",
    "                           'specificity': [specificity],\n",
    "                           'ppv': [ppv],\n",
    "                           'npv': [npv],\n",
    "                            'forest_f1': [forest_f1]})\n",
    "    metrics_df = pd.concat([metrics_df, metric], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542578ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
